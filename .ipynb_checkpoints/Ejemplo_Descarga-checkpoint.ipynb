{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "546b4233-aaff-4485-88b2-99b51efc1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ESFG_utils.ESFG_Download import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a13ad77-4800-4f03-80cc-f9e73c3f9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Area\n",
    "##Santa Marta Colombia\n",
    "XX_lim=np.array((277-360,326-360))#Si pasa por 0 hay que hacerlo en dos veces ejemplo debajo\n",
    "YY_lim=np.array((-57.5,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259ff4a8-c86f-4efa-a1b6-3c1d23eef283",
   "metadata": {},
   "outputs": [],
   "source": [
    "Open_ID        = ''\n",
    "password       = ''\n",
    "server         = 'esgf-data.dkrz.de'\n",
    "project        = 'CMIP5'\n",
    "experiment     = ['historical','rcp45','rcp85']\n",
    "time_frequency = 'day'\n",
    "variables       = ['pr','prc','tasmax','tasmin']\n",
    "domain         = ''\n",
    "path_output    = 'E:/Cambio_Climatico/CMIP5/ESFG/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6316f8c-eb6a-4795-91c9-5fc00cbdcd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salva\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Warning - defaulting to search with facets=*\n",
      "\n",
      "This behavior is kept for backward-compatibility, but ESGF indexes might not\n",
      "successfully perform a distributed search when this option is used, so some\n",
      "results may be missing.  For full results, it is recommended to pass a list of\n",
      "facets of interest when instantiating a context object.  For example,\n",
      "\n",
      "      ctx = conn.new_context(facets='project,experiment_id')\n",
      "\n",
      "Only the facets that you specify will be present in the facets_counts dictionary.\n",
      "\n",
      "This warning is displayed when a distributed search is performed while using the\n",
      "facets=* default, a maximum of once per context object.  To suppress this warning,\n",
      "set the environment variable ESGF_PYCLIENT_NO_FACETS_STAR_WARNING to any value\n",
      "or explicitly use  conn.new_context(facets='*')\n",
      "\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "download_ESGF_data(Open_ID,\n",
    "    password,\n",
    "    server,\n",
    "    project,\n",
    "    experiment,\n",
    "    time_frequency,\n",
    "    variables,\n",
    "    domain,\n",
    "    path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc542dfc-6838-4591-8c43-06ad72bd3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ESGF_data(Open_ID, password, server, project, experiment,time_frequency, variables, domain, path_output):\n",
    "    \"\"\"Esta función nos permite descargar masivamente mediante WGET los diferentes ficheros netcdf que contienen los servidrores de ESGF sobre cambio climático.\n",
    "    \n",
    "    El servidor por defecto que se va a utilizar es: https://esgf-data.dkrz.de/projects/esgf-dkrz/.\n",
    "    \n",
    "    Parámetros:\n",
    "    ---------------------\n",
    "    Open_ID         : string. ID de tu usuario para acceder a la base de datos correspondiente del servidor\n",
    "    password        : string. Contraseña correspondiente a la ID\n",
    "    server          : string. Servidor del que se desea descargar la información. Ejemplo: https://esgf-data.dkrz.de/esg-search\n",
    "    project         : string. Proyecto dentro del servidor del que se quiere descargar los datos. Ejemplo: CORDEX, CMIP5, CMIP6\n",
    "    experiment      : string. Escenarios de cambio climático. Ejemplo: historical, rcp26, rcp45, rcp85\n",
    "    time_frequency  : string. Frecuencia de la base de datos que se quiere. Ejemplo: 1hr, 6hr, day, mon\n",
    "    variable        : string. Variable que se desea descargar: tasmax, tasmin, pr \n",
    "    domain          : string. En el caso de que se desee descargar CORDEX, se debe de incluir el nombre de la malla. Ejemplo: EUR-11\n",
    "    path_output     : string. Directorio donde se desean guardar los ficheros\n",
    "    \n",
    "    Salidas:\n",
    "    ----------------------\n",
    "    Ficheros netcdf para cada uno de los escenarios y modelos solicitados\n",
    "    \n",
    "    \"\"\"\n",
    "    # dir_file=__file__\n",
    "    # os.chdir(dir_file[:-16])\n",
    "    # print(dir_file)\n",
    "    conn = SearchConnection('https://'+server+'/esg-search', distrib=True)\n",
    "    \n",
    "    \n",
    "        \n",
    "    # with open('wget-plantilla-ESGF.sh', \"r+\") as out_file:\n",
    "    #     lines = out_file.readlines()\n",
    "    for exp in experiment:\n",
    "        for v in variables:\n",
    "            not_downloaded=True\n",
    "            try:\n",
    "                if project=='CORDEX':\n",
    "                    lm = LogonManager()\n",
    "                    lm.logoff()\n",
    "                    lm.is_logged_on()\n",
    "                    lm.logon_with_openid(Open_ID, password, bootstrap=True)\n",
    "                    lm.is_logged_on()\n",
    "\n",
    "                    ctx = conn.new_context(\n",
    "                    project=project,\n",
    "                    experiment=experiment,\n",
    "                    time_frequency=time_frequency,\n",
    "                    variable=v,\n",
    "                    domain=domain,)\n",
    "\n",
    "                    info = cx.domain_info(\"EUR-11\")\n",
    "                    [lon_min_,lat_min_]= rotated_grid_transform((lon_min,lat_min), 1, (180+info['pollon'],-info['pollat']))\n",
    "                    [lon_max_,lat_max_]= rotated_grid_transform((lon_max,lat_max), 1, (180+info['pollon'],-info['pollat']))\n",
    "                else:\n",
    "                    ctx = conn.new_context(\n",
    "                    project=project,\n",
    "                    experiment=experiment,\n",
    "                    time_frequency=time_frequency,\n",
    "                    variable=v,)\n",
    "                if ctx.hit_count==0:\n",
    "                    continue\n",
    "                else:\n",
    "                    variable=v\n",
    "                    print('######### Descargando variable '+v+' del experimento '+exp)\n",
    "                    for i in tqdm.tqdm(range(0, ctx.hit_count)):\n",
    "                        result = ctx.search()[i]\n",
    "                        result.dataset_id\n",
    "                        files = result.file_context().search()\n",
    "                        if len(files)==0:\n",
    "                            continue\n",
    "                        else:\n",
    "                            for file in files:\n",
    "                                if variable +'_' in file.download_url:\n",
    "                                    url=file.download_url\n",
    "\n",
    "                                    if os.path.exists(path_output+variable+'/'+file.filename):\n",
    "                                        not_downloaded=False\n",
    "                                    else:\n",
    "                                        not_downloaded=True\n",
    "                                    nnn=0\n",
    "                                    while not_downloaded:\n",
    "                                        try:\n",
    "                                            print('...................Descargando '+url)\n",
    "                                            download_data(path_output+variable+'/'+file.filename+'_erase',file.download_url,file.size)\n",
    "                                            ds = xr.open_dataset(path_output+variable+'/'+file.filename+'_erase')\n",
    "                                            \n",
    "                                            if project=='CORDEX':\n",
    "                                                da = ds[variable].load()\n",
    "                                                var_ds=list()\n",
    "                                                for k in ds[variable].sizes:\n",
    "                                                    var_ds.append(k)\n",
    "                                                if 'rlon' in var_ds:\n",
    "                                                    da = da.sel(rlat=slice(lat_min_-1.5, lat_max_+1.5), \n",
    "                                                                rlon=slice(lon_min_-0.5, lon_max_+0.5))\n",
    "                                                    print('...................Descargando '+url)\n",
    "\n",
    "                                                elif 'lon' in var_ds:\n",
    "                                                    da = da.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "                                                    print('...................Descargando '+url)\n",
    "                                                    \n",
    "                                                else:\n",
    "                                                    print('Sistema de coordenadas no válido')\n",
    "                                                    not_downloaded=False\n",
    "                                            else:\n",
    "                                                \n",
    "                                            #ds = xr.open_dataset(url, engine = \"netcdf4\")\n",
    "                                                ds['lon']=ds.lon-180\n",
    "                                                da = ds[variable].load()\n",
    "                                                da = da.sel(lat = slice(lat_min, lat_max), lon = da.lon[(da.lon>lon_min) & (da.lon<lon_max)].data)\n",
    "                                            #da = da.assign_coords(lon = (((da.lon + 180) % 360) - 180))\n",
    "                                            #da = da.roll(lon = (-np.nonzero(da.lon.values < 0)[0][0]), roll_coords=True)\n",
    "                                            da.to_netcdf(path_output+variable+'/'+file.filename)\n",
    "                                            da.close()\n",
    "                                            ds.close()\n",
    "                                            os.remove(path_output+variable+'/'+file.filename+'_erase')\n",
    "                                            not_downloaded=False\n",
    "                                        except:\n",
    "                                            print('Try again...')\n",
    "                                            nnn=nnn+1\n",
    "                                            if nnn>10:\n",
    "                                                print('No se ha descargado el fichero')\n",
    "                                                break\n",
    "            except:\n",
    "                continue         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88eef5-bbd0-499f-bdaa-35dfe4635269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
